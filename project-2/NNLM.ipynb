{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of NNLM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4aQIHYYJVZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'brown_train.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq9WIOPwAnKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no228r1oJVZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "    \n",
        "def load(filepath, window_size, vocab_size=None):\n",
        "\n",
        "    words = []\n",
        "    with open(filepath, 'r', encoding='utf8') as file:\n",
        "        words = word_tokenize(file.readline())    \n",
        "\n",
        "    x_train, y_train = [], []\n",
        "    for i in range(len(words) - window_size + 1):\n",
        "        x_train.append(words[i: i + window_size - 1])\n",
        "        y_train.append(words[i +  window_size - 1])\n",
        "    \n",
        "    vocab = [word[0] for word in Counter(words).most_common(vocab_size)]\n",
        "    word2id = { vocab[i]: i for i in range(len(vocab)) }\n",
        "    \n",
        "    return np.array(x_train), np.array(y_train)[:,None], np.array(vocab), word2id\n",
        "\n",
        "def load_zh(filepath, window_size, vocab_size=None):\n",
        "\n",
        "    words = []\n",
        "    with open(filepath, 'r', encoding='utf8') as file:\n",
        "        for line in file:\n",
        "            words += word_tokenize(line.strip())\n",
        "        \n",
        "\n",
        "    x_train, y_train = [], []\n",
        "    for i in range(len(words) - window_size + 1):\n",
        "        x_train.append(words[i: i + window_size - 1])\n",
        "        y_train.append(words[i +  window_size - 1])\n",
        "    \n",
        "    vocab = [word[0] for word in Counter(words).most_common(vocab_size)]\n",
        "    word2id = { vocab[i]: i for i in range(len(vocab)) }\n",
        "    \n",
        "    return np.array(x_train), np.array(y_train)[:,None], np.array(vocab), word2id\n",
        "            \n",
        "def convert_to_id(x_train, y_train, vocab):\n",
        "    \n",
        "    word_to_id = {}\n",
        "    for i, vocab in enumerate(vocab):\n",
        "        word_to_id[vocab] = i\n",
        "        \n",
        "    for i in range(len(x_train)):\n",
        "        x_train[i] = [word_to_id[word] for word in x_train[i]]\n",
        "        y_train[i] = word_to_id[y_train[i][0]]\n",
        "        \n",
        "    return x_train.astype(int), y_train.astype(int)\n",
        "\n",
        "\n",
        "def next_batch(x_train, y_train, batch_size):\n",
        "    \n",
        "    num_batch = len(x_train) // batch_size + 1\n",
        "    for n in range(num_batch):        \n",
        "        offset = n * batch_size\n",
        "        x_batch = x_train[offset: offset + batch_size]\n",
        "        y_batch = y_train[offset: offset + batch_size]\n",
        "        \n",
        "        yield x_batch, y_batch\n",
        "        \n",
        "# def convert_to_word(x_train, y_train, id_to_word):\n",
        "#     for i in range(len(x_train)):\n",
        "#         print(x_train[i])\n",
        "#         x_train[i] = id_to_word[x_train[i]]\n",
        "#         y_train[i] = id_to_word[y_train[i]]\n",
        "#     return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4WGvLpMJVZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameter\n",
        "# TODO: change to number of batches \n",
        "batch_size = 30\n",
        "# TODO: edit to be less hacky\n",
        "window_size = 6\n",
        "vocab_size = None\n",
        "hidden_size = 50\n",
        "emb_dim = 60\n",
        "learning_rate = 0.3\n",
        "epoch_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Had-f-TQJwvI",
        "colab_type": "code",
        "outputId": "470f0214-edb4-4593-f73d-b55ccababea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weiDCYWiL2Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: split into train, valid, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEW5yqMxJVZu",
        "colab_type": "code",
        "outputId": "b887134b-0904-47a0-c536-bbb24e1fb3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_raw, y_raw, vocab, word2id = load_zh(filepath, window_size, vocab_size)\n",
        "vocab_size = len(vocab)\n",
        "print('vocab_size: {}'.format(vocab_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 52945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbWHEqDRJjr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath_v = 'brown_valid.txt'\n",
        "x_raw_v, y_raw_v, vocab_v, word2id_v = load_zh(filepath_v, window_size, vocab_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqZ8qrbSJbon",
        "colab_type": "code",
        "outputId": "731c38af-b268-4e4a-fd6d-4da5c4955000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<', '>', 'the', ..., 'lurched', 'muddied', 'dogtrot'],\n",
              "      dtype='<U38')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdynygmUJVZx",
        "colab_type": "code",
        "outputId": "f257dccf-b4fc-474f-e819-1c02a8067f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# integer representations of vocab\n",
        "x_train, y_train = convert_to_id(x_raw, y_raw, vocab)\n",
        "print('Length: {}'.format(len(x_train)))\n",
        "print('Number of batch: {}'.format(len(x_train) / batch_size))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length: 1321189\n",
            "Number of batch: 44039.63333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfo81jKZJsSw",
        "colab_type": "code",
        "outputId": "dc16e956-a14a-49ed-dae2-7a9bff312826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_valid, y_valid = convert_to_id(x_raw_v, y_raw_v, vocab_v)\n",
        "print('Length: {}'.format(len(x_valid)))\n",
        "print('Number of batch: {}'.format(len(x_valid) / batch_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length: 175397\n",
            "Number of batch: 5846.566666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mP2MomyLbD0",
        "colab_type": "code",
        "outputId": "5445af9b-d80a-474f-d119-c376323cb7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1321189, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfZ3NR_AJVZ0",
        "colab_type": "code",
        "outputId": "5bb9437d-0bdc-4116-f8f7-c757aa00369d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import tensorflow as tf\n",
        "# %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQkPaB6VJVZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Parameter Definition\n",
        "\n",
        "\n",
        "# Input && Output\n",
        "input_words = tf.placeholder(dtype=tf.int32, shape=(batch_size, window_size-1))\n",
        "output_word = tf.placeholder(dtype=tf.int32, shape=(batch_size, 1))\n",
        "\n",
        "\n",
        "# Word Features\n",
        "# word embedding matrix\n",
        "# truncated_normal randomly initializes a matrix of the given shape with values from the normal distribution\n",
        "C = tf.Variable(tf.truncated_normal(shape=(vocab_size, emb_dim), mean=-1, stddev=-1), name='word_embedding')\n",
        "\n",
        "\n",
        "# Hidden Layer Weight && Bias\n",
        "H = tf.Variable(tf.random_normal(shape=(hidden_size, (window_size - 1 ) * emb_dim)))\n",
        "d = tf.Variable(tf.random_normal(shape=(hidden_size, )))\n",
        "\n",
        "# Hidden-to-Output Weight && Bias\n",
        "U = tf.Variable(tf.random_normal(shape=(vocab_size, hidden_size)))\n",
        "b = tf.Variable(tf.random_normal(shape=(vocab_size, )))\n",
        "\n",
        "# Projection-to-Output Weight\n",
        "W = tf.Variable(tf.random_normal(shape=(vocab_size, (window_size - 1) * emb_dim)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSbKQ-12JVZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d02b615e-bd6f-4965-dd64-98919c0bca59"
      },
      "source": [
        "# y = b + Wx + Utanh(d + Hx)\n",
        "\n",
        "# x = (C(w(t-1)), C(w(t-2), ..., C(w(t-n+1))), n == window_size\n",
        "with tf.name_scope('Projection_Layer'):\n",
        "  # get the actual embedding vectors from our batch inputs\n",
        "    x  = tf.nn.embedding_lookup(C, input_words) # (batch_size, window_size-1, emb_dim)\n",
        "    x  = tf.reshape(x, shape=(batch_size, (window_size - 1) * emb_dim))\n",
        "    \n",
        "with tf.name_scope('Hidden_Layer'):\n",
        "    Hx = tf.matmul(x, tf.transpose(H)) # (batch_size, hidden_size)\n",
        "    o  = tf.add(d, Hx) # (batch_size, hidden_size)\n",
        "    a  = tf.nn.tanh(o)  # (batch_size, hidden_size)\n",
        "     \n",
        "with tf.name_scope('Output_Layer'):\n",
        "    Ua = tf.matmul(a, tf.transpose(U)) # (batch_size, vocab_size)\n",
        "    Wx = tf.matmul(x, tf.transpose(W)) # (batch_size, vocab_size)\n",
        "    y  = tf.nn.softmax(tf.clip_by_value(tf.add(b, tf.add(Wx, Ua)), 0.0, 10)) # (batch_size, vocab_size)\n",
        "    #ppl = -1*tf.log(y)\n",
        "\n",
        "with tf.name_scope('Loss'):\n",
        "    onehot_tgt = tf.one_hot(tf.squeeze(output_word), vocab_size)  # (batch_size, vocab_size)\n",
        "    loss = -1 * tf.reduce_mean(tf.reduce_sum(tf.log(y) * onehot_tgt, 1)) # 乘 -1 -> maximize loss\n",
        "   \n",
        "with tf.name_scope('Perplexity'):\n",
        "    ppl = tf.math.exp(loss)\n",
        "    #print(ppl)\n",
        "    \n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss) \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ0x6Zu7bYRe",
        "colab_type": "code",
        "outputId": "40bb175e-0218-42ab-b9cf-c744ec0133e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "saver = tf.train.Saver()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMHizXWCJVZ-",
        "colab_type": "code",
        "outputId": "c8c1f43c-67b7-452f-d64c-046ab7187f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True)) as sess:\n",
        "    # initializes all of those variables we declared in earlier cells!\n",
        "    initializer = tf.global_variables_initializer()\n",
        "    initializer.run()\n",
        "    \n",
        "    step = 0\n",
        "    avg_loss_t = 0\n",
        "    avg_loss_v = 0\n",
        "    loss_t = []\n",
        "    loss_v = []\n",
        "    saver.restore(sess, \"/content/gdrive/My Drive/nnlm/final_model.ckpt\")\n",
        "    for epoch in range(epoch_size):\n",
        "        print('epoch no ', epoch)\n",
        "        save_path = saver.save(sess, \"/content/gdrive/My Drive/nnlm/final_model.ckpt\")\n",
        "\n",
        "        for x_batch, y_batch in next_batch(x_train, y_train, batch_size):\n",
        "            # if the batch is smaller than it's supposed to be (i.e. at end of vocab), skip it\n",
        "            # TODO: change this to account for num_batches, not batch_size\n",
        "\n",
        "            if len(x_batch) != batch_size:\n",
        "                continue\n",
        "            # give TF the data to use for all of the calcs in previous cells\n",
        "            feed_dict = {input_words: x_batch, output_word: y_batch}\n",
        "            # here we tell TF to return the loss to us \n",
        "            fetches = [loss, optimizer]\n",
        "            # where the magic happens \n",
        "            Loss, _ = sess.run(fetches, feed_dict)\n",
        "            avg_loss_t += Loss\n",
        "            #ppl = Perplexity\n",
        "            if step % 1000 == 0:\n",
        "                print('Step {}, Loss: {}'.format(step, avg_loss_t / 1000))\n",
        "                #print('Perplexity: {}'.format(ppl))\n",
        "\n",
        "                for valid_x, valid_y in next_batch(x_valid, y_valid, batch_size):\n",
        "                  if len(valid_x) != batch_size:\n",
        "                    continue\n",
        "                  feed_dict = {input_words: valid_x, output_word: valid_y}\n",
        "                  fetches = [loss, optimizer]\n",
        "                  Loss, _ = sess.run(fetches, feed_dict)\n",
        "                  avg_loss_v += Loss\n",
        "                print('Step {}, Loss: {}'.format(step, avg_loss_v / 1000))\n",
        "                loss_t.append(avg_loss_t)\n",
        "                loss_v.append(avg_loss_v)\n",
        "                avg_loss_t = 0\n",
        "                avg_loss_v = 0\n",
        "                \n",
        "            step += 1\n",
        "        \n",
        "    print('Training Done.')\n",
        "    word_embedding = C.eval()\n",
        "    # # TODO: this fails because it's a placeholder. Figure out how to visualize\n",
        "    # # y \n",
        "    # y_vals = y.eval()\n",
        "    \n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/nnlm/final_model.ckpt\n",
            "epoch no  0\n",
            "Step 0, Loss: 0.008834031105041504\n",
            "Step 0, Loss: 15.906856119394302\n",
            "Step 1000, Loss: 6.618669257879257\n",
            "Step 1000, Loss: 15.888002531528473\n",
            "Step 2000, Loss: 6.350076826334\n",
            "Step 2000, Loss: 15.876499027490615\n",
            "Step 3000, Loss: 6.506515859127044\n",
            "Step 3000, Loss: 15.867314840316773\n",
            "Step 4000, Loss: 6.530137540340424\n",
            "Step 4000, Loss: 15.868576750040054\n",
            "Step 5000, Loss: 6.673533667325973\n",
            "Step 5000, Loss: 15.866191981315612\n",
            "Step 6000, Loss: 6.630266601800918\n",
            "Step 6000, Loss: 15.862811940550804\n",
            "Step 7000, Loss: 6.686098099470138\n",
            "Step 7000, Loss: 15.863385906457902\n",
            "Step 8000, Loss: 6.620896711587906\n",
            "Step 8000, Loss: 15.865423483967781\n",
            "Step 9000, Loss: 6.608205669164658\n",
            "Step 9000, Loss: 15.859942431688308\n",
            "Step 10000, Loss: 6.719606333017349\n",
            "Step 10000, Loss: 15.859451622128487\n",
            "Step 11000, Loss: 6.918381294727325\n",
            "Step 11000, Loss: 15.866500587821006\n",
            "Step 12000, Loss: 6.683464585781097\n",
            "Step 12000, Loss: 15.855675251483918\n",
            "Step 13000, Loss: 6.410189059019089\n",
            "Step 13000, Loss: 15.852957130789758\n",
            "Step 14000, Loss: 6.754088258743286\n",
            "Step 14000, Loss: 15.855825881958008\n",
            "Step 15000, Loss: 6.892557843923568\n",
            "Step 15000, Loss: 15.85167550599575\n",
            "Step 16000, Loss: 6.735761759519577\n",
            "Step 16000, Loss: 15.848379934668541\n",
            "Step 17000, Loss: 6.592890516519547\n",
            "Step 17000, Loss: 15.850471469521523\n",
            "Step 18000, Loss: 6.708233429431916\n",
            "Step 18000, Loss: 15.849889559864998\n",
            "Step 19000, Loss: 6.7474704060554505\n",
            "Step 19000, Loss: 15.851259464979172\n",
            "Step 20000, Loss: 6.620610757827759\n",
            "Step 20000, Loss: 15.854101803660393\n",
            "Step 21000, Loss: 6.7937136399745945\n",
            "Step 21000, Loss: 15.852576719760895\n",
            "Step 22000, Loss: 6.78866064620018\n",
            "Step 22000, Loss: 15.851939094543457\n",
            "Step 23000, Loss: 6.712465109109878\n",
            "Step 23000, Loss: 15.855953914523125\n",
            "Step 24000, Loss: 6.750093737125397\n",
            "Step 24000, Loss: 15.857804299116134\n",
            "Step 25000, Loss: 6.490551722764969\n",
            "Step 25000, Loss: 15.851596737146378\n",
            "Step 26000, Loss: 6.603972268104553\n",
            "Step 26000, Loss: 15.854546214580536\n",
            "Step 27000, Loss: 6.654262647151947\n",
            "Step 27000, Loss: 15.850362898111344\n",
            "Step 28000, Loss: 6.620806196689606\n",
            "Step 28000, Loss: 15.853134404540063\n",
            "Step 29000, Loss: 6.766616926908493\n",
            "Step 29000, Loss: 15.854991059184075\n",
            "Step 30000, Loss: 6.711637559175491\n",
            "Step 30000, Loss: 15.846842094421387\n",
            "Step 31000, Loss: 6.652965864181518\n",
            "Step 31000, Loss: 15.84795627450943\n",
            "Step 32000, Loss: 6.707491454601288\n",
            "Step 32000, Loss: 15.843980963468551\n",
            "Step 33000, Loss: 6.513158571839333\n",
            "Step 33000, Loss: 15.84417119526863\n",
            "Step 34000, Loss: 6.272352648854255\n",
            "Step 34000, Loss: 15.841625541210174\n",
            "Step 35000, Loss: 6.922485360622406\n",
            "Step 35000, Loss: 15.842617830038071\n",
            "Step 36000, Loss: 6.91335048365593\n",
            "Step 36000, Loss: 15.845781515836716\n",
            "Step 37000, Loss: 6.884957155704498\n",
            "Step 37000, Loss: 15.845379512906074\n",
            "Step 38000, Loss: 6.897016388893127\n",
            "Step 38000, Loss: 15.83979500079155\n",
            "Step 39000, Loss: 6.574668237686157\n",
            "Step 39000, Loss: 15.839779862642288\n",
            "Step 40000, Loss: 6.426292047023773\n",
            "Step 40000, Loss: 15.840654544949532\n",
            "Step 41000, Loss: 6.059613110303879\n",
            "Step 41000, Loss: 15.841309698224068\n",
            "Step 42000, Loss: 6.2914363741874695\n",
            "Step 42000, Loss: 15.840539097428321\n",
            "Step 43000, Loss: 5.900571766376495\n",
            "Step 43000, Loss: 15.842957804918289\n",
            "Step 44000, Loss: 5.981880566835404\n",
            "Step 44000, Loss: 15.847219594359398\n",
            "Training Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEY_7Zk8SIxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: # y are our logits from the Bengio equation. those logits we must then convert to pseudo probabilities, then normalize via softmax to produce our y_hat.\n",
        "#       y_hat should be (vocabulary length) X (1) in size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt9utADwkSL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ac92d8cf-46fd-418e-942a-c41262b8e25a"
      },
      "source": [
        "loss_t = np.array(loss_t)\n",
        "plt.plot(range(len(loss_t)), np.exp(loss_t/1000))\n",
        "loss_v = np.array(loss_v)\n",
        "plt.plot(range(len(loss_v)), np.exp(loss_v/1000))\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0d82fecedf76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_t\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_v\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_t' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeabkDBJiS3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24c0f44e-5f02-4411-8cfa-0a1bb814d53a"
      },
      "source": [
        "filepath_t = 'brown_test.txt'\n",
        "x_raw_t, y_raw_t, vocab_t, word2id_t = load_zh(filepath_t, window_size, vocab_size)\n",
        "x_test, y_test = convert_to_id(x_raw_t, y_raw_t, vocab_t)\n",
        "print('Length: {}'.format(len(x_test)))\n",
        "print('Number of batch: {}'.format(len(x_test) / batch_size))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length: 189235\n",
            "Number of batch: 6307.833333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riw3EQg5qt3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c7a8ea34-0a4f-448e-bf8c-f0d99fe1609e"
      },
      "source": [
        "avg_loss_test = 0\n",
        "loss_test = []\n",
        "ctr = 0\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
        "\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True)) as sess:\n",
        "  saver.restore(sess, \"/content/gdrive/My Drive/nnlm/final_model.ckpt\")\n",
        "  step = 0\n",
        "  for test_x, test_y in next_batch(x_test, y_test, batch_size):\n",
        "    if len(test_x) != batch_size:\n",
        "        continue\n",
        "    feed_dict = {input_words: test_x, output_word: test_y}\n",
        "    fetches = [loss, optimizer]\n",
        "    # where the magic happens \n",
        "    Loss, _ = sess.run(fetches, feed_dict)\n",
        "    avg_loss_test += Loss\n",
        "    ctr += 1\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "      print('Step {}, Loss: {}'.format(step, avg_loss_test / 1000))\n",
        "      loss_test.append(avg_loss_test/1000)\n",
        "      avg_loss_test = 0\n",
        "    step += 1\n",
        "#print(np.exp(avg_loss_test/ctr))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/nnlm/final_model.ckpt\n",
            "Step 0, Loss: 0.008966852188110351\n",
            "Step 1000, Loss: 9.015638908863068\n",
            "Step 2000, Loss: 8.387402516841888\n",
            "Step 3000, Loss: 8.1041927485466\n",
            "Step 4000, Loss: 7.9367685546875\n",
            "Step 5000, Loss: 7.894798601150513\n",
            "Step 6000, Loss: 7.910759675502777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld6NjpeQscOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd9bbe23-0a45-4586-ff97-75ae8e3767eb"
      },
      "source": [
        "loss_test = np.array(loss_test)\n",
        "plt.plot(range(len(loss_test)), np.exp(loss_test))\n",
        "plt.show()\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL6ySmt4Kvwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ee49bd9-edca-4902-e0fe-40e6521038ee"
      },
      "source": [
        "np.sum(np.exp(loss_test))/len(loss_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1268.636036360928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}