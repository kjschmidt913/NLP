# import math
# def segment(corpus, batch_size):
#     """
#     :param corpus: Corpus to be segmented
#     :param batch_size: Batch size of sequence
#     """
#     batches = math.floor(len(corpus)/30)
#     for i in range(0, len(corpus), batches):
#         yield corpus[i:i + batches]
#
#
# with open('tagged-group3-Train.txt') as f:
#     corpora = [word for line in f for word in line.split()]
#
# segmented_corpus = list(segment(corpora, 30))
# print(len(segmented_corpus))
#
# sliding_window = 5
#
#
# for segments in segmented_corpus:
#     if len(segments) == math.floor(len(corpora)/30):
#         offset = 0
#         while offset != 3:
#             print(segments[offset:sliding_window+offset])
#             offset += 1
import nltk
from construct_vocab import Vocabulary

voc = Vocabulary('Train')

with open('tagged-group3-Train.txt') as f:
    corpora = [word for line in f for word in line.split()]

for words in corpora:
    tokenized_words = nltk.word_tokenize(words)
    for i in tokenized_words:
        voc.add_word(i)

train_vocab_list=[]
for word in range(voc.num_words):
    train_vocab_list.append(voc.to_word(word))
print(len(train_vocab_list))